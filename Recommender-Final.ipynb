{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outfit Recommender\n",
    "\n",
    "Zach Cummings, Austin Martinez, Bowen Wong, Perveen Wong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "productData = pd.read_excel('Behold+product+data+04262021.xlsx')\n",
    "outfits = pd.read_csv('outfit_combinations USC.csv')\n",
    "#additionalTags = pd.read_csv('usc_additional_tags USC.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by importing the two datasets we need for this project. The first dataset, productData, contains information about each product in the catalog, including name, brand, and description. The second dataset, outfits, contains data on premade outfits selected by Behold's experts. Each is important for our recommender algorithm; we'll need the product data to determine which products are most similar to each other, and in the case that we match a product to the user query that is listed in the premade outfits dataset, we'll bring in the rest of that outfit to recommend a relevant, expertly designed outfit to the user. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by creating a dataset called pre (pre-processed) that contains only the columns we need for our recommender. These columns include the \n",
    "\n",
    "- product ID (which we'll use to uniquely identify and pull products into the recommender)\n",
    "- the name, details, brand category, and description (which we'll use to calculate similarity between products and engineer additional features)\n",
    "- the product active variable (which we'll use to give the user the option to only receive recommendations for active products). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = productData[['product_id', 'name', 'details', 'brand_category','description', 'product_active']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we convert the text fields to strings, remove line breaks, and lowercase all text so that we can match stopwords and reduce the total number of unique tokens. We also create a copy of the pre dataset called cat, which we'll use to create a category feature. We create a copy so that if things go wrong we can refer to the pre dataset instead of starting from scratch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-a041e9a35bd7>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pre['name'] = pre['name'].astype(str)\n",
      "<ipython-input-29-a041e9a35bd7>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pre['description'] = pre['description'].astype(str)\n",
      "<ipython-input-29-a041e9a35bd7>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pre['details'] = pre['details'].astype(str)\n",
      "<ipython-input-29-a041e9a35bd7>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pre['brand_category'] = pre['brand_category'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "pre['name'] = pre['name'].astype(str)\n",
    "pre['description'] = pre['description'].astype(str)\n",
    "pre['details'] = pre['details'].astype(str)\n",
    "pre['brand_category'] = pre['brand_category'].astype(str)\n",
    "\n",
    "pre = pre.replace(r'\\\\n',' ', regex=True) \n",
    "\n",
    "pre['description'] = pre['description'].str.lower()\n",
    "pre['name'] = pre['name'].str.lower()\n",
    "pre['details'] = pre['details'].str.lower()\n",
    "pre['brand_category'] = pre['brand_category'].str.lower()\n",
    "\n",
    "cat = pre.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>name</th>\n",
       "      <th>details</th>\n",
       "      <th>brand_category</th>\n",
       "      <th>description</th>\n",
       "      <th>product_active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01EX0PN4J9WRNZH5F93YEX6QAF</td>\n",
       "      <td>khadi stripe shirt-our signature shirt</td>\n",
       "      <td>nan</td>\n",
       "      <td>unknown</td>\n",
       "      <td>our signature khadi shirt\\navailable in black ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01F0C4SKZV6YXS3265JMC39NXW</td>\n",
       "      <td>ruffle market dress loopy pink sistine tomato</td>\n",
       "      <td>nan</td>\n",
       "      <td>unknown</td>\n",
       "      <td>mid-length dress with ruffles and adjustable s...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01EY4Y1BW8VZW51BWG5VZY82XW</td>\n",
       "      <td>ibi slip on raw red knit sneaker women</td>\n",
       "      <td>nan</td>\n",
       "      <td>unknown</td>\n",
       "      <td>ibi slip on raw red knit sneaker women</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01EY50E27A0P5V6KCW01XPDB43</td>\n",
       "      <td>ibi slip on black knit sneaker women</td>\n",
       "      <td>nan</td>\n",
       "      <td>unknown</td>\n",
       "      <td>ibi slip on black knit sneaker women</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01EY6DWHC2W5HPNEGXKEJ4A1CX</td>\n",
       "      <td>catiba pro skate black suede and canvas contra...</td>\n",
       "      <td>nan</td>\n",
       "      <td>unknown</td>\n",
       "      <td>nan</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   product_id  \\\n",
       "0  01EX0PN4J9WRNZH5F93YEX6QAF   \n",
       "1  01F0C4SKZV6YXS3265JMC39NXW   \n",
       "2  01EY4Y1BW8VZW51BWG5VZY82XW   \n",
       "3  01EY50E27A0P5V6KCW01XPDB43   \n",
       "4  01EY6DWHC2W5HPNEGXKEJ4A1CX   \n",
       "\n",
       "                                                name details brand_category  \\\n",
       "0             khadi stripe shirt-our signature shirt     nan        unknown   \n",
       "1      ruffle market dress loopy pink sistine tomato     nan        unknown   \n",
       "2             ibi slip on raw red knit sneaker women     nan        unknown   \n",
       "3               ibi slip on black knit sneaker women     nan        unknown   \n",
       "4  catiba pro skate black suede and canvas contra...     nan        unknown   \n",
       "\n",
       "                                         description  product_active  \n",
       "0  our signature khadi shirt\\navailable in black ...            True  \n",
       "1  mid-length dress with ruffles and adjustable s...            True  \n",
       "2             ibi slip on raw red knit sneaker women           False  \n",
       "3               ibi slip on black knit sneaker women           False  \n",
       "4                                                nan           False  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engineering the Category Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The category variable is extremely important to our recommender. Thus, we put a lot of work into ensuring that products were thoroughly and accurately classified into their respective categories. We chose to create five category classes, four of which we decided to use in our recommender. A recommended outfit consists of a: \n",
    "\n",
    "- bottom\n",
    "- top\n",
    "- shoe\n",
    "- accessory\n",
    "\n",
    "The final category is unknown, which we assigned to products that weren't classified into one of the four above categories. \n",
    "\n",
    "\n",
    "We considered employing a machine learning model to categorize the clothing into these classes, using the pre-made outfit product type field as a class label. However, we wanted to try regex first before spending resources on a complex model, and found that regex did more than a good enough job to be used as the final method for creating the category feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "cat['category'] = np.nan\n",
    "cat['BOTTOM'] = 0\n",
    "cat['TOP'] = 0\n",
    "cat['SHOE'] = 0\n",
    "cat['ACCESSORY'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each category, we replace language representations of that category with a category label. We can then search for that label when assigning a count of occurences of a given label's language representations for a given product. We search for these representations in all four of our main text columns: \n",
    "\n",
    "- description\n",
    "- details\n",
    "- name\n",
    "- brand category\n",
    "\n",
    "When I say language representation, I mean, for example, that a \"SHOE\" could be represented by tokens such as \"sneakers\", \"high heels\", and \"slippers\". We essentially grouped as many representations as we could think of into their respective categories by replacing the representative tokens with the category itself. \n",
    "\n",
    "Note that the development of the list of tokens which could be considered a representation of that product category was an iterative process. We inspected which products were classified as \"unknown\" after each round, and then looked for common clothing items that we weren't including in our regex lists. We continued this process until we were satisfied with the number of product's we had classified. \n",
    "\n",
    "Note also that we perform these replacement searches before lemmatization, which might change the tokens to unrecognizable forms in some instances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bottoms\n",
    "cat['name'] = cat['name'].str\\\n",
    ".replace(r'\\bover-?alls?\\b|\\bjumpsuits?\\b|\\bjeans?\\b|\\bpants?\\b|\\bbottoms?\\b|\\blegs?\\b|\\bslacks?\\b|\\bshorts?\\b|\\bskirts?\\b|\\bunder(?:wear|garments?)\\b|\\bleggings?\\b|\\btrousers?\\b|\\bone-pieces?\\b|\\bone pieces?\\b|\\brompers?\\b|\\bdress(?:es)?\\b|\\bjumpers?\\b|\\bleotards?\\b|\\bonesies?\\b|\\bkhakis\\b|\\bchinos?\\b|\\bculottes?\\b|\\bharems?\\b|\\bjodhpurs?\\b|\\bpegged\\b|\\bsailors?\\b|\\btoreadors?\\b', 'BOTTOM', regex = True)\n",
    "\n",
    "cat['details'] = cat['details'].str\\\n",
    ".replace(r'\\bover-?alls?\\b|\\bjumpsuits?\\b|\\bjeans?\\b|\\bpants?\\b|\\bbottoms?\\b|\\blegs?\\b|\\bslacks?\\b|\\bshorts?\\b|\\bskirts?\\b|\\bunder(?:wear|garments?)\\b|\\bleggings?\\b|\\btrousers?\\b|\\bone-pieces?\\b|\\bone pieces?\\b|\\brompers?\\b|\\bdress(?:es)?\\b|\\bjumpers?\\b|\\bleotards?\\b|\\bonesies?\\b|\\bkhakis\\b|\\bchinos?\\b|\\bculottes?\\b|\\bharems?\\b|\\bjodhpurs?\\b|\\bpegged\\b|\\bsailors?\\b|\\btoreadors?\\b', 'BOTTOM', regex = True)\n",
    "cat['description'] = cat['description'].str\\\n",
    ".replace(r'\\bover-?alls?\\b|\\bjumpsuits?\\b|\\bjeans?\\b|\\bpants?\\b|\\bbottoms?\\b|\\blegs?\\b|\\bslacks?\\b|\\bshorts?\\b|\\bskirts?\\b|\\bunder(?:wear|garments?)\\b|\\bleggings?\\b|\\btrousers?\\b|\\bone-pieces?\\b|\\bone pieces?\\b|\\brompers?\\b|\\bdress(?:es)?\\b|\\bjumpers?\\b|\\bleotards?\\b|\\bonesies?\\b|\\bkhakis\\b|\\bchinos?\\b|\\bculottes?\\b|\\bharems?\\b|\\bjodhpurs?\\b|\\bpegged\\b|\\bsailors?\\b|\\btoreadors?\\b', 'BOTTOM', regex = True)\n",
    "cat['brand_category'] = cat['brand_category'].str\\\n",
    ".replace(r'\\bover-?alls?\\b|\\bjumpsuits?\\b|\\bjeans?\\b|\\bpants?\\b|\\bbottoms?\\b|\\blegs?\\b|\\bslacks?\\b|\\bshorts?\\b|\\bskirts?\\b|\\bunder(?:wear|garments?)\\b|\\bleggings?\\b|\\btrousers?\\b|\\bone-pieces?\\b|\\bone pieces?\\b|\\brompers?\\b|\\bdress(?:es)?\\b|\\bjumpers?\\b|\\bleotards?\\b|\\bonesies?\\b|\\bkhakis\\b|\\bchinos?\\b|\\bculottes?\\b|\\bharems?\\b|\\bjodhpurs?\\b|\\bpegged\\b|\\bsailors?\\b|\\btoreadors?\\b', 'BOTTOM', regex = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we replace the representative tokens with the class token, we search for those tokens in all 4 text columns. We then fill in the cell for the category in question for a given product with the total count of the category token found in all four text columns for that product. \n",
    "\n",
    "Our original design simply filled in the category columns with a binary variable detailing whether or not there was at least one category token in any of the 4 columns for a product, but there were too many instances where two or more categories were present. The counting system allows us to assign a product to the category that is most prevalent in the various text columns for that product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-34-f02a422a1608>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cat['BOTTOM'][row] = cat['name'][row].count('BOTTOM') + cat['description'][row].count('BOTTOM')\\\n"
     ]
    }
   ],
   "source": [
    "#fill in the new category feature tags for bottom products\n",
    "for row in range(len(cat)):\n",
    "    cat['BOTTOM'][row] = cat['name'][row].count('BOTTOM') + cat['description'][row].count('BOTTOM')\\\n",
    "    + cat['details'][row].count('BOTTOM') + cat['brand_category'][row].count('BOTTOM')\n",
    "    \n",
    "bottom_count = len(cat[cat['BOTTOM'] > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we assign a count to a given category for a product, we reset the text columns before searching for instances of the next category, in case that any tokens apply to both. It's unlikely but more of a precaution than anything. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat['name'] = pre['name']\n",
    "cat['details'] = pre['details']\n",
    "cat['description'] = pre['description']\n",
    "cat['brand_category'] = pre['brand_category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tops\n",
    "cat['name'] = cat['name'].str\\\n",
    ".replace(r'\\brobes?\\b|\\bdojos?\\b|\\bturtle-?necks?\\b|\\bgowns?\\b|\\bcover-?ups?\\b|\\bkimonos?\\b|\\bbras?\\b|\\bbreast(?:ed)?\\b|\\bvests?\\b|\\btops?\\b|\\bshirts?\\b|\\bhoodies?\\b|\\bcrewnecks?\\b|\\bv-?necks?\\b|\\bsweat(?:ers?|shirts?)\\b|\\bblouses?\\b|\\btank(?:top)?\\b|\\btee\\b|\\bt-?shirt\\b|\\bcami(?:sole?)?\\b|\\bcardigans?\\b|\\bpull-?overs?\\b|\\bblazers?\\b|\\bjackets?\\b|\\btubes?\\b|\\bwraps?\\b|\\bringers?\\b|\\bsleeves?\\b|\\bcoats?\\b', 'TOP', regex = True)\n",
    "\n",
    "cat['details'] = cat['details'].str\\\n",
    ".replace(r'\\brobes?\\b|\\bdojos?\\b|\\bturtle-?necks?\\b|\\bgowns?\\b|\\bcover-?ups?\\b|\\bkimonos?\\b|\\bbras?\\b|\\bbreast(?:ed)?\\b|\\bvests?\\b|\\btops?\\b|\\bshirts?\\b|\\bhoodies?\\b|\\bcrewnecks?\\b|\\bv-?necks?\\b|\\bsweat(?:ers?|shirts?)\\b|\\bblouses?\\b|\\btank(?:top)?\\b|\\btee\\b|\\bt-?shirt\\b|\\bcami(?:sole?)?\\b|\\bcardigans?\\b|\\bpull-?overs?\\b|\\bblazers?\\b|\\bjackets?\\b|\\btubes?\\b|\\bwraps?\\b|\\bringers?\\b|\\bsleeves?\\b|\\bcoats?\\b', 'TOP', regex = True)\n",
    "\n",
    "cat['description'] = cat['description'].str\\\n",
    ".replace(r'\\brobes?\\b|\\bdojos?\\b|\\bturtle-?necks?\\b|\\bgowns?\\b|\\bcover-?ups?\\b|\\bkimonos?\\b|\\bbras?\\b|\\bbreast(?:ed)?\\b|\\bvests?\\b|\\btops?\\b|\\bshirts?\\b|\\bhoodies?\\b|\\bcrewnecks?\\b|\\bv-?necks?\\b|\\bsweat(?:ers?|shirts?)\\b|\\bblouses?\\b|\\btank(?:top)?\\b|\\btee\\b|\\bt-?shirt\\b|\\bcami(?:sole?)?\\b|\\bcardigans?\\b|\\bpull-?overs?\\b|\\bblazers?\\b|\\bjackets?\\b|\\btubes?\\b|\\bwraps?\\b|\\bringers?\\b|\\bsleeves?\\b|\\bcoats?\\b', 'TOP', regex = True)\n",
    "\n",
    "cat['brand_category'] = cat['brand_category'].str\\\n",
    ".replace(r'\\brobes?\\b|\\bdojos?\\b|\\bturtle-?necks?\\b|\\bgowns?\\b|\\bcover-?ups?\\b|\\bkimonos?\\b|\\bbras?\\b|\\bbreast(?:ed)?\\b|\\bvests?\\b|\\btops?\\b|\\bshirts?\\b|\\bhoodies?\\b|\\bcrewnecks?\\b|\\bv-?necks?\\b|\\bsweat(?:ers?|shirts?)\\b|\\bblouses?\\b|\\btank(?:top)?\\b|\\btee\\b|\\bt-?shirt\\b|\\bcami(?:sole?)?\\b|\\bcardigans?\\b|\\bpull-?overs?\\b|\\bblazers?\\b|\\bjackets?\\b|\\btubes?\\b|\\bwraps?\\b|\\bringers?\\b|\\bsleeves?\\b|\\bcoats?\\b', 'TOP', regex = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-37-10861d2e3ace>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cat['TOP'][row] = cat['name'][row].count('TOP') + cat['description'][row].count('TOP')\\\n"
     ]
    }
   ],
   "source": [
    "#fill in the new category feature tags for top products\n",
    "for row in range(len(cat)):\n",
    "    cat['TOP'][row] = cat['name'][row].count('TOP') + cat['description'][row].count('TOP')\\\n",
    "    + cat['details'][row].count('TOP') + cat['brand_category'][row].count('TOP')\n",
    "    \n",
    "top_count = len(cat[cat['TOP'] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat['name'] = pre['name']\n",
    "cat['details'] = pre['details']\n",
    "cat['description'] = pre['description']\n",
    "cat['brand_category'] = pre['brand_category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shoes\n",
    "cat['name'] = cat['name'].str\\\n",
    ".replace(r'\\bsneakers?\\b|\\bheels?\\b|\\bsandals?\\b|\\bflip-?(?:flops?)\\b|\\bwedges?\\b|\\bpumps?\\b|\\bboots?\\b|\\bslippers?\\b|\\bhi-tops?\\b|\\bshoes?\\b|\\bloafers?\\b|\\bcrocs?\\b|\\bmoccasins?\\b|\\bmukluks?\\b|\\bopen-?toed?\\b|\\boxfords?\\b|\\bpenny?\\b|\\bplatforms?\\b|\\bslides?\\b|\\bclogs?\\b', 'SHOE', regex = True)\n",
    "\n",
    "cat['details'] = cat['details'].str\\\n",
    ".replace(r'\\bsneakers?\\b|\\bheels?\\b|\\bsandals?\\b|\\bflip-?(?:flops?)\\b|\\bwedges?\\b|\\bpumps?\\b|\\bboots?\\b|\\bslippers?\\b|\\bhi-tops?\\b|\\bshoes?\\b|\\bloafers?\\b|\\bcrocs?\\b|\\bmoccasins?\\b|\\bmukluks?\\b|\\bopen-?toed?\\b|\\boxfords?\\b|\\bpenny?\\b|\\bplatforms?\\b|\\bslides?\\b|\\bclogs?\\b', 'SHOE', regex = True)\n",
    "\n",
    "cat['description'] = cat['description'].str\\\n",
    ".replace(r'\\bsneakers?\\b|\\bheels?\\b|\\bsandals?\\b|\\bflip-?(?:flops?)\\b|\\bwedges?\\b|\\bpumps?\\b|\\bboots?\\b|\\bslippers?\\b|\\bhi-tops?\\b|\\bshoes?\\b|\\bloafers?\\b|\\bcrocs?\\b|\\bmoccasins?\\b|\\bmukluks?\\b|\\bopen-?toed?\\b|\\boxfords?\\b|\\bpenny?\\b|\\bplatforms?\\b|\\bslides?\\b|\\bclogs?\\b', 'SHOE', regex = True)\n",
    "\n",
    "cat['brand_category'] = cat['brand_category'].str\\\n",
    ".replace(r'\\bsneakers?\\b|\\bheels?\\b|\\bsandals?\\b|\\bflip-?(?:flops?)\\b|\\bwedges?\\b|\\bpumps?\\b|\\bboots?\\b|\\bslippers?\\b|\\bhi-tops?\\b|\\bshoes?\\b|\\bloafers?\\b|\\bcrocs?\\b|\\bmoccasins?\\b|\\bmukluks?\\b|\\bopen-?toed?\\b|\\boxfords?\\b|\\bpenny?\\b|\\bplatforms?\\b|\\bslides?\\b|\\bclogs?\\b', 'SHOE', regex = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-40-79b5f3439623>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cat['SHOE'][row] = cat['name'][row].count('SHOE') + cat['description'][row].count('SHOE')\\\n"
     ]
    }
   ],
   "source": [
    "#fill in the new category feature tags for shoe products\n",
    "for row in range(len(cat)):\n",
    "    cat['SHOE'][row] = cat['name'][row].count('SHOE') + cat['description'][row].count('SHOE')\\\n",
    "    + cat['details'][row].count('SHOE') + cat['brand_category'][row].count('SHOE')\n",
    "    \n",
    "shoe_count = len(cat[cat['SHOE'] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat['name'] = pre['name']\n",
    "cat['details'] = pre['details']\n",
    "cat['description'] = pre['description']\n",
    "cat['brand_category'] = pre['brand_category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accessories\n",
    "cat['name'] = cat['name'].str\\\n",
    ".replace(r'\\bmasks?\\b|\\bfacemasks?\\b|\\bglasses?\\b|\\bsunglasses?\\b|\\brims?\\b|\\bbandanas?\\b|\\bbelts?\\b|\\bframes?\\b|\\bcaps?\\b|\\bbrims?\\b|\\bhats?\\b|\\bclutch\\b|\\bpurses?\\b|\\bhandbags?\\b|\\bcross-body\\b|\\btotes?\\b|\\bbags?\\b|\\bpack\\b|\\bsatchel\\b|\\bhobo\\b|\\bbaguette\\b|\\bshopper\\b|\\bwristlet\\b|\\bbucket\\b|\\bscar(?:f|ves)\\b|\\bwrap\\b|\\binfinty\\b|\\bcowl\\b|\\bcircle\\b|\\bmuffler\\b|\\btriangle\\b|\\bwatch(?:es)?\\b|\\bbracelets?\\b|\\bchokers?\\b|\\bnecklaces?\\b|\\banklets?\\b|\\bpendants?\\b|\\bbangles?\\b|\\bcuffs?\\b|\\brings?\\b|\\bbrooch\\b|\\blockets?\\b|\\bmedallions?\\b|\\bpendants?\\b|\\bearr?ings?\\b|\\bhairpins?\\b|hair\\b', 'ACCESSORY', regex = True)\n",
    "\n",
    "cat['details'] = cat['details'].str\\\n",
    ".replace(r'\\bmasks?\\b|\\bfacemasks?\\b|\\bglasses?\\b|\\bsunglasses?\\b|\\brims?\\b|\\bbandanas?\\b|\\bbelts?\\b|\\bframes?\\b|\\bcaps?\\b|\\bbrims?\\b|\\bhats?\\b|\\bclutch\\b|\\bpurses?\\b|\\bhandbags?\\b|\\bcross-body\\b|\\btotes?\\b|\\bbags?\\b|\\bpack\\b|\\bsatchel\\b|\\bhobo\\b|\\bbaguette\\b|\\bshopper\\b|\\bwristlet\\b|\\bbucket\\b|\\bscar(?:f|ves)\\b|\\bwrap\\b|\\binfinty\\b|\\bcowl\\b|\\bcircle\\b|\\bmuffler\\b|\\btriangle\\b|\\bwatch(?:es)?\\b|\\bbracelets?\\b|\\bchokers?\\b|\\bnecklaces?\\b|\\banklets?\\b|\\bpendants?\\b|\\bbangles?\\b|\\bcuffs?\\b|\\brings?\\b|\\bbrooch\\b|\\blockets?\\b|\\bmedallions?\\b|\\bpendants?\\b|\\bearr?ings?\\b|\\bhairpins?\\b|hair\\b', 'ACCESSORY', regex = True)\n",
    "\n",
    "cat['description'] = cat['description'].str\\\n",
    ".replace(r'\\bmasks?\\b|\\bfacemasks?\\b|\\bglasses?\\b|\\bsunglasses?\\b|\\brims?\\b|\\bbandanas?\\b|\\bbelts?\\b|\\bframes?\\b|\\bcaps?\\b|\\bbrims?\\b|\\bhats?\\b|\\bclutch\\b|\\bpurses?\\b|\\bhandbags?\\b|\\bcross-body\\b|\\btotes?\\b|\\bbags?\\b|\\bpack\\b|\\bsatchel\\b|\\bhobo\\b|\\bbaguette\\b|\\bshopper\\b|\\bwristlet\\b|\\bbucket\\b|\\bscar(?:f|ves)\\b|\\bwrap\\b|\\binfinty\\b|\\bcowl\\b|\\bcircle\\b|\\bmuffler\\b|\\btriangle\\b|\\bwatch(?:es)?\\b|\\bbracelets?\\b|\\bchokers?\\b|\\bnecklaces?\\b|\\banklets?\\b|\\bpendants?\\b|\\bbangles?\\b|\\bcuffs?\\b|\\brings?\\b|\\bbrooch\\b|\\blockets?\\b|\\bmedallions?\\b|\\bpendants?\\b|\\bearr?ings?\\b|\\bhairpins?\\b|hair\\b', 'ACCESSORY', regex = True)\n",
    "\n",
    "cat['brand_category'] = cat['brand_category'].str\\\n",
    ".replace(r'\\bmasks?\\b|\\bfacemasks?\\b|\\bglasses?\\b|\\bsunglasses?\\b|\\brims?\\b|\\bbandanas?\\b|\\bbelts?\\b|\\bframes?\\b|\\bcaps?\\b|\\bbrims?\\b|\\bhats?\\b|\\bclutch\\b|\\bpurses?\\b|\\bhandbags?\\b|\\bcross-body\\b|\\btotes?\\b|\\bbags?\\b|\\bpack\\b|\\bsatchel\\b|\\bhobo\\b|\\bbaguette\\b|\\bshopper\\b|\\bwristlet\\b|\\bbucket\\b|\\bscar(?:f|ves)\\b|\\bwrap\\b|\\binfinty\\b|\\bcowl\\b|\\bcircle\\b|\\bmuffler\\b|\\btriangle\\b|\\bwatch(?:es)?\\b|\\bbracelets?\\b|\\bchokers?\\b|\\bnecklaces?\\b|\\banklets?\\b|\\bpendants?\\b|\\bbangles?\\b|\\bcuffs?\\b|\\brings?\\b|\\bbrooch\\b|\\blockets?\\b|\\bmedallions?\\b|\\bpendants?\\b|\\bearr?ings?\\b|\\bhairpins?\\b|hair\\b', 'ACCESSORY', regex = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-43-215a9aadaee4>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cat['ACCESSORY'][row] = cat['name'][row].count('ACCESSORY') + cat['description'][row].count('ACCESSORY')\\\n"
     ]
    }
   ],
   "source": [
    "#fill in the new category feature tags for shoe products\n",
    "for row in range(len(cat)):\n",
    "    cat['ACCESSORY'][row] = cat['name'][row].count('ACCESSORY') + cat['description'][row].count('ACCESSORY')\\\n",
    "    + cat['details'][row].count('ACCESSORY') + cat['brand_category'][row].count('ACCESSORY')\n",
    "    \n",
    "accessory_count = len(cat[cat['ACCESSORY'] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat['name'] = pre['name']\n",
    "cat['details'] = pre['details']\n",
    "cat['description'] = pre['description']\n",
    "cat['brand_category'] = pre['brand_category']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll use a few loops to assign the class with the highest count for each product to the category column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-46-7046c829bc7a>:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cat['category'][row] = true_classes[0]\n",
      "C:\\Users\\zapcu\\anaconda3\\new\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n",
      "<ipython-input-46-7046c829bc7a>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cat['category'][row] = 'BOTTOM'\n",
      "<ipython-input-46-7046c829bc7a>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cat['category'][row] = 'UNKNOWN'\n",
      "<ipython-input-46-7046c829bc7a>:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cat['category'][row] = 'TOP'\n",
      "<ipython-input-46-7046c829bc7a>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cat['category'][row] = 'SHOE'\n",
      "<ipython-input-46-7046c829bc7a>:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cat['category'][row] = 'ACCESSORY'\n"
     ]
    }
   ],
   "source": [
    "#create a temporary subset dataframe including only the category count columns\n",
    "temp = cat[['BOTTOM', 'TOP', 'SHOE', 'ACCESSORY']]\n",
    "\n",
    "#for each row (product) in the dataframe...\n",
    "for row in range(len(cat)):\n",
    "    true_classes = []\n",
    "    for col in temp.columns:\n",
    "        if temp[col][row] > 0:\n",
    "            #build a list of categories that have at least 1 occurence for that product. \n",
    "            true_classes.append(col)\n",
    "    \n",
    "    #count the total number of occurrences for all categories for each product\n",
    "    class_count = temp.iloc[row, :].sum()\n",
    "    \n",
    "    #If no classes have occurences for the product, assign UNKNOWN\n",
    "    if class_count == 0:\n",
    "        cat['category'][row] = 'UNKNOWN'\n",
    "    #If the total occurence count across all categories is the same as the maximum category's count, then assign that \n",
    "    #class to the product\n",
    "    elif class_count == temp.iloc[row, :].max():\n",
    "        cat['category'][row] = true_classes[0]\n",
    "    #otherwise, there's at least one occurence for multiple categories for a given product. In this case we enter a subloop.  \n",
    "    else:\n",
    "        #we check if each category's column is equal to the max across the row. If it is we assign that category. \n",
    "        #In the event of a tie, the priority goes in the order in which the categories appear in this sub loop. \n",
    "        if cat['BOTTOM'][row] == temp.iloc[row, :].max():\n",
    "            cat['category'][row] = 'BOTTOM'\n",
    "        elif cat['TOP'][row]  == temp.iloc[row, :].max():\n",
    "            cat['category'][row] = 'TOP'\n",
    "        elif cat['SHOE'][row]  == temp.iloc[row, :].max():\n",
    "            cat['category'][row] = 'SHOE'\n",
    "        else:\n",
    "            cat['category'][row] = 'ACCESSORY'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the counts for the classes we've assigned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TOP          20755\n",
       "BOTTOM       18495\n",
       "UNKNOWN      10234\n",
       "ACCESSORY     6873\n",
       "SHOE          4998\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat['category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assigned 51,121 of the records to a category that wasn't unknown. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51121"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat) - len(cat[cat['category'] == 'UNKNOWN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a look at our iterative process mentioned above for examining the unknown products for trends, or representations for categories we might be missing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat[cat['category'] == 'UNKNOWN']['description'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of the remaining descriptions aren't really even clothing, or they're obscure clothing items, so they really should be classified as unknown. We could spend all day picking off the remaining items and categorizing them into the regex streams, but what we have will give us over 51,000 products to work with in our recommender, which we are happy with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = cat[['product_id', 'category']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we subset the dataframe to only the product id column (which we'll use to merge the categories to the rest of our recommender input data) and the category column. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zapcu\\anaconda3\\new\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "#%pip install gensim \n",
    "import gensim \n",
    "from gensim.parsing.preprocessing import remove_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({'neither', 'thus', 'since', 'five', 'against', 'cry', 'third', 'each', 'anything', 'using', 'may', 'beside', 'ten', 'within', 'sincere', 'should', 'did', 'done', 'various', 'six', 'behind', 'fifteen', 'through', 'somewhere', 'also', 'i', 'nowhere', 'such', 'while', 'ever', 'twenty', 'than', 'during', 'do', 'thereby', 'rather', 'who', 'most', 'others', 'which', 'always', 'becoming', 'me', 'many', 'please', 'can', 'formerly', 'already', 'thick', 'fifty', 'then', 'after', 'several', 'too', 'more', 'among', 'yourself', 'almost', 'has', 'were', 'if', 'say', 'anywhere', 'hence', 'over', 'give', 'towards', 'across', 'made', 'with', 'there', 'computer', 'how', 'every', 'someone', 'take', 'last', 'less', 'name', 'indeed', 'wherein', 'often', 'is', 'further', 'either', 'why', 'cannot', 'enough', 'whereby', 'thence', 'call', 'those', 'him', 'amongst', 'does', 'km', 'an', 'well', 'whole', 'all', 'only', 'top', 'we', 'amoungst', 'and', 'whenever', 'ours', 'two', 'make', 'not', 'it', 'full', 'without', 'ie', 'twelve', 'three', 'a', 'both', 'until', 'they', 'their', 'becomes', 'de', 'beforehand', 'became', 'same', 'otherwise', 'few', 'go', 'much', 're', 'seem', 'what', 'kg', 'yours', 'hereby', 'although', 'hers', 'afterwards', 'fire', 'whoever', 'themselves', 'per', 'wherever', 'here', 'no', 'noone', 'from', 'system', 'regarding', 'next', 'around', 'never', 'throughout', 'part', 'didn', 'eg', 'have', 'thin', 'become', 'herein', 'for', 'moreover', 'she', 'to', 'keep', 'about', 'cant', 'inc', 'none', 'forty', 'might', 'be', 'hundred', 'interest', 'am', 'he', 'where', 'was', 'whereupon', 'hereafter', 'his', 'meanwhile', 'down', 'seeming', 'mostly', 'nor', 'something', 'before', 'very', 'show', 'even', 'latter', 'amount', 'thru', 'whereafter', 'them', 'whose', 'whereas', 'etc', 'beyond', 'whom', 'thereafter', 'by', 'had', 'on', 'first', 'nine', 'you', 'whither', 'into', 'hereupon', 'alone', 'thereupon', 'anyone', 'herself', 'our', 'found', 'see', 'own', 'one', 'sixty', 'so', 'now', 'move', 'bottom', 'everywhere', 'mill', 'detail', 'else', 'find', 'whether', 'serious', 'everything', 'anyhow', 'get', 'eleven', 'could', 'another', 'quite', 'sometimes', 'unless', 'as', 'any', 'doesn', 'ourselves', 'really', 'up', 'ltd', 'latterly', 'her', 'being', 'due', 'nobody', 'just', 'nevertheless', 'your', 'therefore', 'under', 'former', 'when', 'anyway', 'somehow', 'put', 'below', 'everyone', 'empty', 'but', 'myself', 'its', 'itself', 'seemed', 'off', 'these', 'bill', 'or', 'four', 'however', 'himself', 'front', 'sometime', 'onto', 'my', 'the', 'other', 'couldnt', 'though', 'except', 'that', 'must', 'will', 'are', 'yourselves', 'yet', 'because', 'mine', 'fill', 'once', 'again', 'un', 'between', 'whatever', 'eight', 'would', 'describe', 'namely', 'together', 'besides', 'back', 'at', 'us', 'nothing', 'co', 'seems', 'therein', 'least', 'hasnt', 'of', 'doing', 'perhaps', 'been', 'via', 'some', 'this', 'don', 'con', 'along', 'upon', 'elsewhere', 'used', 'side', 'whence', 'still', 'out', 'above', 'in', 'toward'})\n"
     ]
    }
   ],
   "source": [
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "print(STOPWORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define a function for removing stopwords, and apply it to all of our text columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def punc_remove(text):\n",
    "    \n",
    "    return re.sub(r'[^\\w\\s]','',text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also convert all of our text columns to strings, and lowercase them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-54-112118ed40fa>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pre['name'] = pre['name'].astype(str)\n",
      "<ipython-input-54-112118ed40fa>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pre['description'] = pre['description'].astype(str)\n",
      "<ipython-input-54-112118ed40fa>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pre['details'] = pre['details'].astype(str)\n",
      "<ipython-input-54-112118ed40fa>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pre['brand_category'] = pre['brand_category'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "pre = productData[['product_id', 'name', 'details', 'brand_category','description', 'product_active']]\n",
    "\n",
    "pre['name'] = pre['name'].astype(str)\n",
    "pre['description'] = pre['description'].astype(str)\n",
    "pre['details'] = pre['details'].astype(str)\n",
    "pre['brand_category'] = pre['brand_category'].astype(str)\n",
    "\n",
    "pre = pre.replace(r'\\\\n',' ', regex = True) \n",
    "\n",
    "pre['name'] = pre['name'].apply(punc_remove)\n",
    "pre['description'] = pre['description'].apply(punc_remove)\n",
    "pre['details'] = pre['details'].apply(punc_remove)\n",
    "pre['brand_category'] = pre['brand_category'].apply(punc_remove)\n",
    "\n",
    "pre['description'] = pre['description'].str.lower()\n",
    "pre['name'] = pre['name'].str.lower()\n",
    "pre['details'] = pre['details'].str.lower()\n",
    "pre['brand_category'] = pre['brand_category'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we remove all stopwords after inspecting the list above for any stopwords we might not want to remove. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pre['name'] = pre['name'].apply(remove_stopwords)\n",
    "pre['details'] = pre['details'].apply(remove_stopwords)\n",
    "pre['description'] = pre['description'].apply(remove_stopwords)\n",
    "pre['brand_category'] = pre['brand_category'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll use spacy's lemmatizer to lemmatize the text columns. These are the columns we'll be using for our cosine distance calculator in our recommender, so its important to lemmatize in order to ensure words that are semantically the same are represented as the same in the text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install spacy\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "import pandas as pd\n",
    "def lemmatize_text(text):\n",
    "    sentence = ''\n",
    "    lemmas = []\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        lemmas.append(token.lemma_)\n",
    "    for token in lemmas:\n",
    "        sentence = sentence + token + ' '\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for lemmatization\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# function to convert nltk tag to wordnet tag\n",
    "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return None\n",
    "\n",
    "def lemmatize_sentence(sentence):\n",
    "    #tokenize the sentence and find the POS tag for each token\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))  \n",
    "    #tuple of (token, wordnet_tag)\n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_tag_to_wordnet_tag(x[1])), nltk_tagged)\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            #if there is no available tag, append the token as is\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:        \n",
    "            #else use the tag to lemmatize the token\n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    return \" \".join(lemmatized_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre['name'] = pre['name'].apply(lemmatize_sentence)\n",
    "pre['details'] = pre['details'].apply(lemmatize_sentence)\n",
    "pre['description'] = pre['description'].apply(lemmatize_sentence)\n",
    "pre['brand_category'] = pre['brand_category'].apply(lemmatize_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We merge the cleaned text columns with the product category column we created earlier. We also include the product_active column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pre.merge(cat, on = 'product_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>name</th>\n",
       "      <th>details</th>\n",
       "      <th>brand_category</th>\n",
       "      <th>description</th>\n",
       "      <th>product_active</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01EX0PN4J9WRNZH5F93YEX6QAF</td>\n",
       "      <td>khadi stripe shirtour signature shirt</td>\n",
       "      <td>nan</td>\n",
       "      <td>unknown</td>\n",
       "      <td>signature khadi shirt available black white ea...</td>\n",
       "      <td>True</td>\n",
       "      <td>TOP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01F0C4SKZV6YXS3265JMC39NXW</td>\n",
       "      <td>ruffle market dress loopy pink sistine tomato</td>\n",
       "      <td>nan</td>\n",
       "      <td>unknown</td>\n",
       "      <td>midlength dress ruffle adjustable strap bias c...</td>\n",
       "      <td>True</td>\n",
       "      <td>BOTTOM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01EY4Y1BW8VZW51BWG5VZY82XW</td>\n",
       "      <td>ibi slip raw red knit sneaker woman</td>\n",
       "      <td>nan</td>\n",
       "      <td>unknown</td>\n",
       "      <td>ibi slip raw red knit sneaker woman</td>\n",
       "      <td>False</td>\n",
       "      <td>SHOE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01EY50E27A0P5V6KCW01XPDB43</td>\n",
       "      <td>ibi slip black knit sneaker woman</td>\n",
       "      <td>nan</td>\n",
       "      <td>unknown</td>\n",
       "      <td>ibi slip black knit sneaker woman</td>\n",
       "      <td>False</td>\n",
       "      <td>SHOE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01EY6DWHC2W5HPNEGXKEJ4A1CX</td>\n",
       "      <td>catiba pro skate black suede canvas contrast t...</td>\n",
       "      <td>nan</td>\n",
       "      <td>unknown</td>\n",
       "      <td>nan</td>\n",
       "      <td>False</td>\n",
       "      <td>SHOE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61350</th>\n",
       "      <td>01EYB5ERGYPFNGM6C9QK7Q9EV0</td>\n",
       "      <td>bowvida mule black suede kidskin</td>\n",
       "      <td>feminine flat mule square shape v line gently ...</td>\n",
       "      <td>sandalssales</td>\n",
       "      <td>flat bowvida mule black suede ideal spring sum...</td>\n",
       "      <td>False</td>\n",
       "      <td>SHOE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61351</th>\n",
       "      <td>01EHWTBFP368Q035FW95TRJDAY</td>\n",
       "      <td>sandale vida mule tangerine suede kidskin</td>\n",
       "      <td>feminine flat mule square shape v line gently ...</td>\n",
       "      <td>flat sandalsarchives</td>\n",
       "      <td>flat vida mule tangerine suede comfortable fem...</td>\n",
       "      <td>False</td>\n",
       "      <td>SHOE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61352</th>\n",
       "      <td>01EHWTCFTPPSCW10D4XBQZF28H</td>\n",
       "      <td>bowvida mule fuschia suede kidskin</td>\n",
       "      <td>feminine flat mule square shape v line gently ...</td>\n",
       "      <td>flat sandalsarchives</td>\n",
       "      <td>flat bowvida mule fuschia suede ideal spring s...</td>\n",
       "      <td>False</td>\n",
       "      <td>SHOE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61353</th>\n",
       "      <td>01EYB5B5FH7JESXF82ZEMVXZMS</td>\n",
       "      <td>vida mule silver metalize leather</td>\n",
       "      <td>feminine flat mule square shape v line gently ...</td>\n",
       "      <td>sandalssales</td>\n",
       "      <td>flat vida mule silver metalize leather comfort...</td>\n",
       "      <td>False</td>\n",
       "      <td>SHOE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61354</th>\n",
       "      <td>01EHWTF4VNZ6FPF2836A0CFEEG</td>\n",
       "      <td>bowvida mule bronze metalize leather</td>\n",
       "      <td>feminine flat mule square shape v line gently ...</td>\n",
       "      <td>flat sandalsarchives</td>\n",
       "      <td>flat bowvida mule bronze leather ideal spring ...</td>\n",
       "      <td>False</td>\n",
       "      <td>SHOE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61355 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       product_id  \\\n",
       "0      01EX0PN4J9WRNZH5F93YEX6QAF   \n",
       "1      01F0C4SKZV6YXS3265JMC39NXW   \n",
       "2      01EY4Y1BW8VZW51BWG5VZY82XW   \n",
       "3      01EY50E27A0P5V6KCW01XPDB43   \n",
       "4      01EY6DWHC2W5HPNEGXKEJ4A1CX   \n",
       "...                           ...   \n",
       "61350  01EYB5ERGYPFNGM6C9QK7Q9EV0   \n",
       "61351  01EHWTBFP368Q035FW95TRJDAY   \n",
       "61352  01EHWTCFTPPSCW10D4XBQZF28H   \n",
       "61353  01EYB5B5FH7JESXF82ZEMVXZMS   \n",
       "61354  01EHWTF4VNZ6FPF2836A0CFEEG   \n",
       "\n",
       "                                                    name  \\\n",
       "0                  khadi stripe shirtour signature shirt   \n",
       "1          ruffle market dress loopy pink sistine tomato   \n",
       "2                    ibi slip raw red knit sneaker woman   \n",
       "3                      ibi slip black knit sneaker woman   \n",
       "4      catiba pro skate black suede canvas contrast t...   \n",
       "...                                                  ...   \n",
       "61350                   bowvida mule black suede kidskin   \n",
       "61351          sandale vida mule tangerine suede kidskin   \n",
       "61352                 bowvida mule fuschia suede kidskin   \n",
       "61353                  vida mule silver metalize leather   \n",
       "61354               bowvida mule bronze metalize leather   \n",
       "\n",
       "                                                 details  \\\n",
       "0                                                    nan   \n",
       "1                                                    nan   \n",
       "2                                                    nan   \n",
       "3                                                    nan   \n",
       "4                                                    nan   \n",
       "...                                                  ...   \n",
       "61350  feminine flat mule square shape v line gently ...   \n",
       "61351  feminine flat mule square shape v line gently ...   \n",
       "61352  feminine flat mule square shape v line gently ...   \n",
       "61353  feminine flat mule square shape v line gently ...   \n",
       "61354  feminine flat mule square shape v line gently ...   \n",
       "\n",
       "             brand_category  \\\n",
       "0                   unknown   \n",
       "1                   unknown   \n",
       "2                   unknown   \n",
       "3                   unknown   \n",
       "4                   unknown   \n",
       "...                     ...   \n",
       "61350          sandalssales   \n",
       "61351  flat sandalsarchives   \n",
       "61352  flat sandalsarchives   \n",
       "61353          sandalssales   \n",
       "61354  flat sandalsarchives   \n",
       "\n",
       "                                             description  product_active  \\\n",
       "0      signature khadi shirt available black white ea...            True   \n",
       "1      midlength dress ruffle adjustable strap bias c...            True   \n",
       "2                    ibi slip raw red knit sneaker woman           False   \n",
       "3                      ibi slip black knit sneaker woman           False   \n",
       "4                                                    nan           False   \n",
       "...                                                  ...             ...   \n",
       "61350  flat bowvida mule black suede ideal spring sum...           False   \n",
       "61351  flat vida mule tangerine suede comfortable fem...           False   \n",
       "61352  flat bowvida mule fuschia suede ideal spring s...           False   \n",
       "61353  flat vida mule silver metalize leather comfort...           False   \n",
       "61354  flat bowvida mule bronze leather ideal spring ...           False   \n",
       "\n",
       "      category  \n",
       "0          TOP  \n",
       "1       BOTTOM  \n",
       "2         SHOE  \n",
       "3         SHOE  \n",
       "4         SHOE  \n",
       "...        ...  \n",
       "61350     SHOE  \n",
       "61351     SHOE  \n",
       "61352     SHOE  \n",
       "61353     SHOE  \n",
       "61354     SHOE  \n",
       "\n",
       "[61355 rows x 7 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfits = pd.read_csv('outfit_combinations USC.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the cosine query function\n",
    "def cosineQuery(docs, query):\n",
    "    \"\"\"\n",
    "    docs: string of text for a document\n",
    "    query: query string\n",
    "\n",
    "    return: cosine similarity between query and all docs\n",
    "    \"\"\"\n",
    "    TFIDF = TfidfVectorizer().fit_transform(docs)\n",
    "    qTFIDF = TfidfVectorizer().fit(docs)\n",
    "    qTFIDF = qTFIDF.transform([query])\n",
    "    return cosine_similarity(qTFIDF, TFIDF).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get first outfit from the curated outfit data\n",
    "def getOutfit(productID, rec):\n",
    "    \"\"\"\n",
    "    productID: product ID\n",
    "    rec: recommended outfit combination dataframe\n",
    "\n",
    "    return: cosine similarity between query and all docs\n",
    "    \"\"\"\n",
    "    outfitID = rec[rec['product_id'] == productID].iloc[0,:][0]\n",
    "    df = rec[rec['outfit_id'] == outfitID].loc[:, ['outfit_item_type', 'product_full_name']]\n",
    "    d = df.to_dict(orient='records')\n",
    "    returnDict = {}\n",
    "    for i in d:\n",
    "        returnDict[i['outfit_item_type']] = i['product_full_name']\n",
    "    return returnDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our final recommender algorithm gives users the option on whether or not they want to include inactive products in the recommendation set. We chose to include this option instead of by default recommending only active products, since most of the products in the dataset are inactive: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['product_active'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, limitToActive=False): \n",
    "    \"\"\"\n",
    "    query is a string that is passed in by the user, and this function returns a \n",
    "    dictionary of outfit results. \n",
    "    Example:\n",
    "    search(\"pleated casual skirt\") -> { \n",
    "        \"top\": \"...\",\n",
    "        \"bottom\": \"...\",\n",
    "        \"shoe\": \"...\"\n",
    "    } \"\"\"   \n",
    "    if (query == '' or len(query) <= 0 or not query):\n",
    "        print('Query Empty...')\n",
    "        return\n",
    "    query = query.lower()\n",
    "    \n",
    "    # GET the text\n",
    "    dat = merged.copy()\n",
    "    rec = outfits\n",
    "    \n",
    "    # Combine columns and create new text column\n",
    "    text = []\n",
    "    for index, row in dat.drop(['product_id', 'product_active', 'category'], axis=1).iterrows():\n",
    "        s = ''\n",
    "        for i in row:\n",
    "            temp = str(i)\n",
    "            if (temp != 'NaN' and temp != 'unknown'):\n",
    "                s += temp\n",
    "        text.append(' '.join(re.findall(r'[a-z]+', s)))\n",
    "    dat['text'] = text\n",
    "    \n",
    "    # Run the cosine query\n",
    "    cos = cosineQuery(dat['text'], query)\n",
    "    dat['similarities'] = cos\n",
    "    \n",
    "    # Only consider active products if `limitToActive` is flagged\n",
    "    if(limitToActive):\n",
    "        dat = dat[dat['product_active']]\n",
    "        \n",
    "    dat = dat[dat['category'] != 'UNKNOWN']\n",
    "    \n",
    "    # Sort and get top result \n",
    "    top = dat.sort_values('similarities', ascending=False).reset_index(drop=True).iloc[0]\n",
    "    \n",
    "    # If the top result is in the outfit combos, return the outfit\n",
    "    if (rec[rec['product_id'] == top['product_id']].shape[0] > 0):\n",
    "        return getOutfit(top['product_id'], rec)\n",
    "    \n",
    "    # Remove the top result and its class from the full dataset\n",
    "    # We can do both in one go\n",
    "    df = dat[dat['category'] != top['category']].copy()\n",
    "    \n",
    "    # Query again with data from the top result, whatever that may be\n",
    "    cos = cosineQuery(df['text'], top['text'])\n",
    "    df['similarities'] = cos\n",
    "    \n",
    "    # Select the top results for the remaining classes\n",
    "    returnDict = {top['category']: top['name']}\n",
    "    classMask = dat['category'].unique().tolist()\n",
    "    if (top['category'] in classMask):\n",
    "        classMask.remove(top['category'])\n",
    "    for i in classMask:\n",
    "        temp = df[df['category'] == i].sort_values('similarities', ascending=False).reset_index(drop=True).iloc[0]\n",
    "        returnDict[temp['category']] = temp['name']\n",
    "    return returnDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TOP': 'crystal star', 'BOTTOM': 'starry night dress', 'SHOE': 'ibi slip white knit sneaker woman', 'ACCESSORY': 'talisman energy earring'}\n"
     ]
    }
   ],
   "source": [
    "# Run the recommendation function\n",
    "print(search('plain white tee', limitToActive = False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
